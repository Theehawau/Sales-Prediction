{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts/')))\n",
    "# Import utility scripts\n",
    "from data_cleaner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Functions Imported!!!\n"
     ]
    }
   ],
   "source": [
    "util = Clean_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Sales Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_features(df,col):\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    df['Year'] = df[col].dt.year\n",
    "    df['Month'] = df[col].dt.month\n",
    "    df['Day'] = df[col].dt.day\n",
    "    df['WeekOfYear'] = df[col].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_db = util.read_data('../data/store.csv')\n",
    "train_db = util.read_data('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017209, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_db.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
       "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
       "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
       "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
       "       'Promo2SinceYear', 'PromoInterval'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.merge(left=train_db,right=store_db,on='Store',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 12:32:14.518 INFO    numexpr.utils: NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "# Process data for dashboard\n",
    "train = db[(db.Open != 0) & (db.Sales>0)]\n",
    "def process(df):\n",
    "    \n",
    "#     #Replacing null values for CompetitionOpenSinceMonth,CompetitionOpenSinceYear\n",
    "#     util.fill_null('CompetitionOpenSinceMonth',df,df['CompetitionOpenSinceMonth'].mean())\n",
    "#     util.fill_null('CompetitionOpenSinceYear',df,df['CompetitionOpenSinceYear'].mean())\n",
    "#     util.fill_null('CompetitionDistance',df,df['CompetitionDistance'].mean())\n",
    "#     df.fillna(0, inplace=True)\n",
    "    \n",
    "    #label encode categorical_features  \n",
    "    mapping = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    df.StoreType.replace(mapping, inplace=True)\n",
    "    df.Assortment.replace(mapping, inplace=True)\n",
    "    \n",
    "    df['IsHoliday'] = df.StateHoliday.map({'0':0,'a':1,'b':1,'c':1,0:0})\n",
    "    df['IsWeekend'] = df.DayOfWeek.map({6:1,7:1,1:0,2:0,3:0,4:0,5:0})\n",
    "    \n",
    "    #Get date features  \n",
    "    get_date_features(df, 'Date')\n",
    "    \n",
    "    #Calculate competitor open time in months\n",
    "    df['CompetitionOpenMonths'] = 12 * (df.Year - df.CompetitionOpenSinceYear) + \\\n",
    "    (df.Month - df.CompetitionOpenSinceMonth)\n",
    "    df['CompetitionOpenMonths'] = df['CompetitionOpenMonths'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    # calculate promo2 open time in months\n",
    "    df['Promo2OpenMonths'] = 12 * (df.Year - df.Promo2SinceYear) + \\\n",
    "        (df.WeekOfYear - df.Promo2SinceWeek) / 4.0\n",
    "    df['Promo2OpenMonths'] = df['Promo2OpenMonths'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    #Check if month in promo2 month\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    df['month_str'] = df.Month.map(month2str)\n",
    "    def check(row):\n",
    "        if isinstance(row['PromoInterval'],str) and row['month_str'] in row['PromoInterval']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    df['IsPromoMonth'] =  df.apply(lambda row: check(row),axis=1)  \n",
    "    # select the features we need\n",
    "    features = ['Store', 'DayOfWeek', 'Promo', 'IsHoliday', 'SchoolHoliday',\n",
    "       'StoreType', 'Assortment', 'CompetitionDistance',\n",
    "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
    "       'Promo2SinceWeek', 'Promo2SinceYear', 'Year', 'Month', 'Day',\n",
    "       'WeekOfYear', 'CompetitionOpenMonths', 'Promo2OpenMonths', 'IsPromoMonth','IsWeekend']\n",
    "    X = df[features]\n",
    "    y = df[['Sales']]\n",
    "#     feature = df[features]\n",
    "#     target = df[['Sales','Date']]\n",
    "#     feature.reset_index().drop(columns=['index'], inplace =True)\n",
    "#     feature.to_csv('../Data/X.csv',index=False)\n",
    "#     target.reset_index().drop(columns=['index'], inplace =True)\n",
    "#     target.to_csv('../Data/Y.csv',index=False)\n",
    "    return X,y\n",
    "    \n",
    "X,y = process(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.reset_index().drop(columns=['index'], inplace =True)\n",
    "X.reset_index().drop(columns=['index'], inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = '../data/X.csv'\n",
    "version = 'v2'\n",
    "mlflow.log_param('data_url', data_url)\n",
    "mlflow.log_param('data_version', version)\n",
    "mlflow.log_param('input_rows',X.shape[0])\n",
    "mlflow.log_param('input_cols', X.shape[1])\n",
    "\n",
    "cols_x = pd.DataFrame(list(X.columns))\n",
    "cols_x.to_csv('features.csv', header=False, index=False)\n",
    "mlflow.log_artifact('features.csv')\n",
    "\n",
    "\n",
    "cols_y = pd.DataFrame(list(y.columns))\n",
    "cols_y.to_csv('target.csv', header=False, index=False)\n",
    "mlflow.log_artifact('target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting to test and train sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=15, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor(n_estimators = 15)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930.7845249825285\n",
      "0.909921023685128\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metrics({'RMSE':np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "                    'R2':r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(clf.feature_importances_, index=features)\n",
    "feat_importances.sort_values(ascending = True).plot(kind='barh')\n",
    "plt.xlabel('importance')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessor Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "   transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor',RandomForestRegressor())\n",
    "           ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_model = pipeline.fit(X_train, y_train)\n",
    "print (rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is chosen as loss function because the dataset contains outliers that are important to the business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "predictions = rf_model.predict(X_test)\n",
    "print (f'r2_score : {r2_score(y_test, predictions)}\\n\\\n",
    "RMSE:{np.sqrt(mean_squared_error(y_test, predictions))}\\\n",
    " ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
